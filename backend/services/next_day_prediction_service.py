"""
NextDayPredictionService - ä¸‹ä¸ªäº¤æ˜“æ—¥é¢„æµ‹æœåŠ¡

åŸºäºèµ„é‡‘æµå‘ã€çƒ­åº¦æ•°æ®çš„é‡åŒ–é¢„æµ‹ç®—æ³•ï¼Œåˆ†æä¸‹ä¸ªäº¤æ˜“æ—¥å¯èƒ½çš„çƒ­é—¨æ¦‚å¿µæ–¹å‘å’Œä¸ªè‚¡æ¨èã€‚

æ ¸å¿ƒç®—æ³•ï¼š
1. èµ„é‡‘æµå‘åŠ¨é‡åˆ†æï¼ˆæœ€è¿‘3-5å¤©å‡€æµå…¥è¶‹åŠ¿ï¼‰
2. æ¿å—çƒ­åº¦åŠ é€Ÿåº¦ï¼ˆçƒ­åº¦å˜åŒ–ç‡ï¼‰
3. æ¦‚å¿µå…±æŒ¯å¼ºåº¦ï¼ˆå¤šè‚¡è”åŠ¨ï¼‰
4. ä¸»åŠ›èµ„é‡‘å¸ƒå±€ï¼ˆå¤§å•å‡€ä¹°å…¥ï¼‰
5. æŠ€æœ¯å½¢æ€å…±æŒ¯ï¼ˆå‡çº¿ã€çªç ´ï¼‰
"""
import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Tuple
from datetime import date, datetime, timedelta
import logging
import json
from db.database import get_db, get_raw_connection
from sqlalchemy import text
from etl.trade_date_adapter import TradeDateAdapter
from etl.concept_filter import should_filter_concept
from db.virtual_board_repository import VirtualBoardRepository

logger = logging.getLogger(__name__)


class NextDayPredictionService:
    """
    ä¸‹ä¸ªäº¤æ˜“æ—¥é¢„æµ‹æœåŠ¡
    
    æ¯åŠå°æ—¶è¿è¡Œä¸€æ¬¡ï¼Œåˆ†ææœ€æ–°æ•°æ®ï¼Œç”Ÿæˆé¢„æµ‹ç»“æœ
    æ–°äº¤æ˜“æ—¥ä¹‹å‰ä¿æŒé¢„æµ‹ç»“æœç¨³å®š
    """
    
    # é¢„æµ‹æ¨¡å‹å‚æ•°
    PARAMS = {
        # èµ„é‡‘æµå‘æƒé‡
        'weight_money_flow': 0.35,
        # çƒ­åº¦æƒé‡
        'weight_hot_rank': 0.25,
        # åŠ¨é‡æƒé‡
        'weight_momentum': 0.20,
        # å…±æŒ¯å¼ºåº¦æƒé‡
        'weight_resonance': 0.20,
        
        # èµ„é‡‘æµå‘åˆ†æå‚æ•°
        'money_flow_days': 3,           # åˆ†ææœ€è¿‘Nå¤©èµ„é‡‘æµå‘
        'min_sector_inflow': 5000,      # æ¿å—æœ€å°å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
        
        # çƒ­åº¦åˆ†æå‚æ•°
        'hot_rank_weight_decay': 0.8,   # çƒ­åº¦æ—¶é—´è¡°å‡ç³»æ•°
        'min_hot_count': 3,             # æœ€å°çƒ­é—¨è‚¡æ•°é‡
        
        # åŠ¨é‡åˆ†æå‚æ•°
        'momentum_days': 5,             # åŠ¨é‡è®¡ç®—å¤©æ•°
        'min_momentum': 0.02,           # æœ€å°åŠ¨é‡é˜ˆå€¼(2%)
        
        # ä¸ªè‚¡ç­›é€‰å‚æ•°
        'top_sectors': 5,               # æ¨èæ¿å—æ•°é‡
        'top_stocks_per_sector': 5,     # æ¯ä¸ªæ¿å—æ¨èè‚¥ç¾Šæ•°ï¼ˆå¢åŠ ä»¥ç¡®ä¿å»é‡åè¶³å¤Ÿï¼‰
        'total_recommended_stocks': 10, # æ€»æ¨èè‚¥ç¾Šæ•°
        'min_stock_score': 50,          # æœ€ä½æ¨èåˆ†æ•°ï¼ˆé™ä½ä»¥å¢åŠ å€™é€‰ï¼‰
    }
    
    @classmethod
    def generate_prediction(cls, force: bool = False) -> Dict:
        """
        ç”Ÿæˆä¸‹ä¸ªäº¤æ˜“æ—¥é¢„æµ‹
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        try:
            # è·å–å½“å‰æ—¥æœŸä¿¡æ¯
            today = date.today()
            current_time = datetime.now()
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°çš„é¢„æµ‹
            # è§„åˆ™ï¼šéäº¤æ˜“æ—¥æˆ–æ”¶ç›˜åï¼ˆ15:30åï¼‰ä¿æŒç¨³å®šï¼Œä¸é‡æ–°ç”Ÿæˆ
            is_trading_day = TradeDateAdapter.is_trading_day(today)
            is_after_close = current_time.hour >= 15 and current_time.minute >= 30
            
            # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
            next_trading_day = TradeDateAdapter.get_next_trading_day(today)
            
            # æ£€æŸ¥ç¼“å­˜
            if not force:
                cached = cls._get_cached_prediction(next_trading_day)
                if cached:
                    # å¦‚æœæ˜¯æ”¶ç›˜åæˆ–éäº¤æ˜“æ—¥ï¼Œç›´æ¥è¿”å›ç¼“å­˜
                    if not is_trading_day or is_after_close:
                        logger.info(f"ä½¿ç”¨ç¼“å­˜çš„é¢„æµ‹ç»“æœï¼ˆéäº¤æ˜“æ—¶æ®µï¼‰: {next_trading_day}")
                        return cached
                    # å¦‚æœç¼“å­˜æ—¶é—´åœ¨30åˆ†é’Ÿå†…ï¼Œä¹Ÿè¿”å›ç¼“å­˜
                    cache_time = datetime.fromisoformat(cached.get('generated_at', '2000-01-01T00:00:00'))
                    if (current_time - cache_time).total_seconds() < 1800:
                        logger.info(f"ä½¿ç”¨ç¼“å­˜çš„é¢„æµ‹ç»“æœï¼ˆ30åˆ†é’Ÿå†…ï¼‰: {next_trading_day}")
                        return cached
            
            logger.info(f"å¼€å§‹ç”Ÿæˆ {next_trading_day} çš„é¢„æµ‹...")
            
            # è·å–æœ€æ–°çš„æœ‰æ•°æ®çš„äº¤æ˜“æ—¥
            latest_trade_date = cls._get_latest_data_date()
            if not latest_trade_date:
                logger.warning("æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸ")
                return {'success': False, 'message': 'æ— æ•°æ®'}
            
            logger.info(f"ä½¿ç”¨äº¤æ˜“æ—¥æœŸ {latest_trade_date} çš„æ•°æ®è¿›è¡Œé¢„æµ‹")
            
            # 1. åˆ†ææ¿å—èµ„é‡‘æµå‘
            sector_analysis = cls._analyze_sector_money_flow(latest_trade_date)
            
            # 2. åˆ†æçƒ­åº¦æ•°æ®
            hot_analysis = cls._analyze_hot_rank(latest_trade_date)
            
            # 3. è®¡ç®—æ¿å—ç»¼åˆå¾—åˆ†
            sector_scores = cls._calculate_sector_scores(sector_analysis, hot_analysis)
            
            # 4. ç”Ÿæˆæ¿å—é¢„æµ‹
            sector_predictions = cls._generate_sector_predictions(sector_scores, sector_analysis, hot_analysis)
            
            # 5. ç­›é€‰æ¨èä¸ªè‚¡
            stock_recommendations = cls._recommend_stocks(sector_predictions, latest_trade_date)
            
            # 6. ç”Ÿæˆé¢„æµ‹æè¿°
            prediction_description = cls._generate_prediction_description(
                sector_predictions, stock_recommendations, latest_trade_date
            )
            
            # æ„å»ºé¢„æµ‹ç»“æœ
            result = {
                'success': True,
                'target_date': next_trading_day.isoformat(),
                'data_date': latest_trade_date.isoformat(),
                'generated_at': current_time.isoformat(),
                'description': prediction_description,
                'sector_predictions': sector_predictions[:cls.PARAMS['top_sectors']],
                'stock_recommendations': stock_recommendations[:cls.PARAMS['total_recommended_stocks']],
                'analysis_summary': {
                    'top_sectors_count': len(sector_predictions),
                    'recommended_stocks_count': len(stock_recommendations),
                    'data_freshness': 'real-time' if is_trading_day and not is_after_close else 'post-market',
                }
            }
            
            # ä¿å­˜åˆ°ç¼“å­˜
            cls._save_prediction_cache(next_trading_day, result)
            
            logger.info(f"é¢„æµ‹ç”Ÿæˆå®Œæˆ: {len(sector_predictions)} ä¸ªæ¿å—, {len(stock_recommendations)} åªä¸ªè‚¡")
            return result
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé¢„æµ‹å¤±è´¥: {e}", exc_info=True)
            return {'success': False, 'message': str(e)}
    
    @classmethod
    def _get_latest_data_date(cls) -> Optional[date]:
        """è·å–æ•°æ®åº“ä¸­æœ€æ–°çš„æœ‰æ•°æ®çš„äº¤æ˜“æ—¥æœŸ"""
        try:
            with get_db() as db:
                result = db.execute(text("""
                    SELECT MAX(trade_date) as max_date
                    FROM sector_money_flow
                """))
                row = result.fetchone()
                if row and row[0]:
                    return row[0] if isinstance(row[0], date) else datetime.strptime(str(row[0]), '%Y-%m-%d').date()
        except Exception as e:
            logger.error(f"è·å–æœ€æ–°æ•°æ®æ—¥æœŸå¤±è´¥: {e}")
        return None
    
    @classmethod
    def _analyze_sector_money_flow(cls, trade_date: date) -> Dict[str, Dict]:
        """
        åˆ†ææ¿å—èµ„é‡‘æµå‘
        
        è¿”å›: {sector_name: {inflow_total, inflow_trend, inflow_acceleration, ...}}
        """
        try:
            days = cls.PARAMS['money_flow_days']
            
            with get_db() as db:
                # è·å–æœ€è¿‘Nå¤©çš„æ¿å—èµ„é‡‘æµå‘
                query = text("""
                    SELECT 
                        sector_name,
                        trade_date,
                        main_net_inflow,
                        super_large_inflow,
                        large_inflow
                    FROM sector_money_flow
                    WHERE trade_date <= :trade_date
                    ORDER BY trade_date DESC
                """)
                
                result = db.execute(query, {'trade_date': trade_date})
                rows = result.fetchall()
            
            if not rows:
                return {}
            
            # æŒ‰æ¿å—åˆ†ç»„
            sector_data = {}
            for row in rows:
                sector_name = row[0]
                if sector_name not in sector_data:
                    sector_data[sector_name] = []
                sector_data[sector_name].append({
                    'trade_date': row[1],
                    'main_net_inflow': float(row[2]) if row[2] else 0,
                    'super_large_inflow': float(row[3]) if row[3] else 0,
                    'large_inflow': float(row[4]) if row[4] else 0,
                })
            
            # è®¡ç®—æ¯ä¸ªæ¿å—çš„èµ„é‡‘æµå‘æŒ‡æ ‡
            analysis = {}
            for sector_name, data_list in sector_data.items():
                # åªå–æœ€è¿‘Nå¤©
                recent_data = sorted(data_list, key=lambda x: x['trade_date'], reverse=True)[:days]
                
                if len(recent_data) < 2:
                    continue
                
                # è®¡ç®—æ€»æµå…¥
                total_inflow = sum(d['main_net_inflow'] for d in recent_data)
                
                # è®¡ç®—æµå…¥è¶‹åŠ¿ï¼ˆçº¿æ€§å›å½’æ–œç‡ï¼‰
                inflows = [d['main_net_inflow'] for d in reversed(recent_data)]
                x = np.arange(len(inflows))
                if len(inflows) >= 2:
                    slope = np.polyfit(x, inflows, 1)[0]
                else:
                    slope = 0
                
                # è®¡ç®—æµå…¥åŠ é€Ÿåº¦ï¼ˆäºŒé˜¶å¯¼æ•°è¿‘ä¼¼ï¼‰
                if len(inflows) >= 3:
                    acceleration = inflows[-1] - 2 * inflows[-2] + inflows[-3] if len(inflows) >= 3 else 0
                else:
                    acceleration = 0
                
                # æœ€è¿‘ä¸€å¤©çš„æµå…¥
                latest_inflow = recent_data[0]['main_net_inflow']
                
                # å¤§å•å æ¯”
                total_large = sum(d['super_large_inflow'] + d['large_inflow'] for d in recent_data)
                large_ratio = total_large / total_inflow if total_inflow > 0 else 0
                
                analysis[sector_name] = {
                    'inflow_total': total_inflow,
                    'inflow_trend': slope,
                    'inflow_acceleration': acceleration,
                    'latest_inflow': latest_inflow,
                    'large_ratio': large_ratio,
                    'data_days': len(recent_data),
                }
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†ææ¿å—èµ„é‡‘æµå‘å¤±è´¥: {e}", exc_info=True)
            return {}
    
    @classmethod
    def _analyze_hot_rank(cls, trade_date: date) -> Dict[str, Dict]:
        """
        åˆ†æçƒ­åº¦æ¦œæ•°æ®
        
        è¿”å›: {sector_name: {hot_count, avg_rank, hot_score, ...}}
        """
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çƒ­åº¦æ¦œæ•°æ®ï¼ˆä¼˜å…ˆä»sheep_basicè·å–æ­£ç¡®çš„åç§°ï¼‰
                query = text("""
                    SELECT 
                        hr.sheep_code,
                        COALESCE(sb.sheep_name, hr.sheep_name) as sheep_name,
                        hr.`rank`,
                        hr.hot_score,
                        scm.concept_id,
                        ct.concept_name
                    FROM market_hot_rank hr
                    LEFT JOIN sheep_basic sb ON hr.sheep_code = sb.sheep_code AND sb.is_active = 1
                    LEFT JOIN sheep_concept_mapping scm ON hr.sheep_code = scm.sheep_code
                    LEFT JOIN concept_theme ct ON scm.concept_id = ct.concept_id AND ct.is_active = 1
                    WHERE hr.trade_date = :trade_date
                    ORDER BY hr.`rank` ASC
                    LIMIT 200
                """)
                
                result = db.execute(query, {'trade_date': trade_date})
                rows = result.fetchall()
            
            if not rows:
                return {}
            
            # è¾…åŠ©å‡½æ•°ï¼šéªŒè¯åç§°æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯ä»£ç æ ¼å¼ï¼‰
            def get_valid_name(name, code):
                if not name or not name.strip():
                    return code
                name_clean = name.strip()
                # å¦‚æœæ˜¯6ä½çº¯æ•°å­—ï¼Œè®¤ä¸ºæ˜¯ä»£ç 
                if len(name_clean) == 6 and name_clean.isdigit():
                    return code
                # å¦‚æœä»¥SHæˆ–SZå¼€å¤´åè·Ÿ6ä½æ•°å­—ï¼Œä¹Ÿè®¤ä¸ºæ˜¯ä»£ç 
                if (name_clean.startswith('SH') or name_clean.startswith('SZ')) and len(name_clean) == 8 and name_clean[2:].isdigit():
                    return code
                return name_clean
            
            # æŒ‰æ¦‚å¿µ/æ¿å—åˆ†ç»„ç»Ÿè®¡
            sector_hot = {}
            for row in rows:
                concept_name = row[5]
                if not concept_name:
                    continue
                
                if concept_name not in sector_hot:
                    sector_hot[concept_name] = {
                        'stocks': [],
                        'ranks': [],
                        'hot_scores': [],
                    }
                
                sheep_code = row[0]
                sheep_name = get_valid_name(row[1], sheep_code)
                
                sector_hot[concept_name]['stocks'].append({
                    'sheep_code': sheep_code,
                    'sheep_name': sheep_name,
                    'rank': row[2],
                    'hot_score': float(row[3]) if row[3] else 0,
                })
                sector_hot[concept_name]['ranks'].append(row[2])
                if row[3]:
                    sector_hot[concept_name]['hot_scores'].append(float(row[3]))
            
            # è®¡ç®—æ¯ä¸ªæ¿å—çš„çƒ­åº¦æŒ‡æ ‡
            analysis = {}
            for sector_name, data in sector_hot.items():
                hot_count = len(data['stocks'])
                if hot_count < cls.PARAMS['min_hot_count']:
                    continue
                
                avg_rank = np.mean(data['ranks']) if data['ranks'] else 999
                avg_hot_score = np.mean(data['hot_scores']) if data['hot_scores'] else 0
                
                # çƒ­åº¦å¾—åˆ†ï¼ˆè€ƒè™‘æ•°é‡å’Œæ’åï¼‰
                # æ’åè¶Šé å‰è¶Šå¥½ï¼Œæ•°é‡è¶Šå¤šè¶Šå¥½
                hot_score = hot_count * 10 + (200 - avg_rank) * 0.5 + avg_hot_score * 0.1
                
                analysis[sector_name] = {
                    'hot_count': hot_count,
                    'avg_rank': avg_rank,
                    'avg_hot_score': avg_hot_score,
                    'hot_score': hot_score,
                    'top_stocks': sorted(data['stocks'], key=lambda x: x['rank'])[:5],
                }
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†æçƒ­åº¦æ¦œå¤±è´¥: {e}", exc_info=True)
            return {}
    
    @classmethod
    def _calculate_sector_scores(cls, sector_analysis: Dict, hot_analysis: Dict) -> List[Tuple[str, float, Dict]]:
        """
        è®¡ç®—æ¿å—ç»¼åˆå¾—åˆ†
        
        Returns: [(sector_name, score, details), ...]
        """
        scores = []
        
        # è·å–è™šæ‹Ÿæ¿å—æ˜ å°„ï¼ˆsource_concept -> [virtual_board, ...]ï¼‰
        concept_to_virtual = VirtualBoardRepository.get_concept_to_virtual_boards()
        
        # åˆå¹¶æ‰€æœ‰æ¿å—ï¼Œå¹¶æŒ‰è™šæ‹Ÿæ¿å—èšåˆ
        all_sectors = set(sector_analysis.keys()) | set(hot_analysis.keys())
        
        # å…ˆèšåˆåˆ°è™šæ‹Ÿæ¿å—
        virtual_sector_data = {}  # {virtual_name: {'money_list': [], 'hot_list': [], 'source_sectors': []}}
        
        for sector_name in all_sectors:
            # è¿‡æ»¤é»‘åå•æ¿å—
            if should_filter_concept(sector_name):
                continue
            
            # è·å–è™šæ‹Ÿæ¿å—åï¼ˆå¦‚æœæœ‰æ˜ å°„åˆ™ç”¨æ˜ å°„ï¼Œå¦åˆ™ç”¨åŸåï¼‰
            virtual_boards = concept_to_virtual.get(sector_name, [sector_name])
            # å–ç¬¬ä¸€ä¸ªè™šæ‹Ÿæ¿å—ï¼ˆä¸»æ˜ å°„ï¼‰
            virtual_name = virtual_boards[0] if virtual_boards else sector_name
            
            # è™šæ‹Ÿæ¿å—ä¹Ÿéœ€è¦è¿‡æ»¤é»‘åå•
            if should_filter_concept(virtual_name):
                continue
            
            if virtual_name not in virtual_sector_data:
                virtual_sector_data[virtual_name] = {
                    'money_list': [],
                    'hot_list': [],
                    'source_sectors': [],
                }
            
            money_data = sector_analysis.get(sector_name, {})
            hot_data = hot_analysis.get(sector_name, {})
            
            if money_data:
                virtual_sector_data[virtual_name]['money_list'].append(money_data)
            if hot_data:
                virtual_sector_data[virtual_name]['hot_list'].append(hot_data)
            virtual_sector_data[virtual_name]['source_sectors'].append(sector_name)
        
        # è®¡ç®—æ¯ä¸ªè™šæ‹Ÿæ¿å—çš„ç»¼åˆå¾—åˆ†
        for virtual_name, data in virtual_sector_data.items():
            # èšåˆèµ„é‡‘æ•°æ®ï¼ˆå–æœ€å¤§å€¼æˆ–æ±‚å’Œï¼‰
            money_data = {}
            if data['money_list']:
                money_data = {
                    'inflow_total': sum(m.get('inflow_total', 0) for m in data['money_list']),
                    'inflow_trend': max((m.get('inflow_trend', 0) for m in data['money_list']), default=0),
                    'inflow_acceleration': max((m.get('inflow_acceleration', 0) for m in data['money_list']), default=0),
                }
            
            # èšåˆçƒ­åº¦æ•°æ®
            hot_data = {}
            if data['hot_list']:
                # åˆå¹¶æ‰€æœ‰top_stocks
                all_top_stocks = []
                for h in data['hot_list']:
                    all_top_stocks.extend(h.get('top_stocks', []))
                # æŒ‰rankæ’åºå»é‡
                seen_codes = set()
                unique_stocks = []
                for stock in sorted(all_top_stocks, key=lambda x: x.get('rank', 999)):
                    if stock['sheep_code'] not in seen_codes:
                        seen_codes.add(stock['sheep_code'])
                        unique_stocks.append(stock)
                
                hot_data = {
                    'hot_count': sum(h.get('hot_count', 0) for h in data['hot_list']),
                    'avg_rank': min((h.get('avg_rank', 999) for h in data['hot_list']), default=999),
                    'hot_score': sum(h.get('hot_score', 0) for h in data['hot_list']),
                    'top_stocks': unique_stocks[:10],  # ä¿ç•™æ›´å¤šè‚¥ç¾Š
                }
            
            # èµ„é‡‘æµå‘å¾—åˆ†ï¼ˆ0-100ï¼‰
            money_score = 0
            if money_data:
                inflow = money_data.get('inflow_total', 0)
                trend = money_data.get('inflow_trend', 0)
                
                # å‡€æµå…¥å¾—åˆ†ï¼ˆ-50åˆ°+50ï¼‰
                if inflow > 0:
                    money_score = min(50, inflow / 10000 * 10)  # æ¯äº¿å…ƒ10åˆ†ï¼Œæœ€é«˜50åˆ†
                else:
                    money_score = max(-50, inflow / 10000 * 5)  # æµå‡ºå‡åˆ†
                
                # è¶‹åŠ¿åŠ åˆ†ï¼ˆ-20åˆ°+20ï¼‰
                if trend > 0:
                    money_score += min(20, trend / 1000 * 5)
                else:
                    money_score += max(-20, trend / 1000 * 2)
                
                # åŠ é€Ÿåº¦åŠ åˆ†ï¼ˆ-10åˆ°+10ï¼‰
                accel = money_data.get('inflow_acceleration', 0)
                if accel > 0:
                    money_score += min(10, accel / 1000 * 2)
                
                # æ ‡å‡†åŒ–åˆ°0-100
                money_score = max(0, min(100, money_score + 50))
            
            # çƒ­åº¦å¾—åˆ†ï¼ˆ0-100ï¼‰
            hot_score = 0
            if hot_data:
                hot_score = min(100, hot_data.get('hot_score', 0))
            
            # åŠ¨é‡å¾—åˆ†ï¼ˆç®€åŒ–ï¼šä½¿ç”¨çƒ­åº¦å˜åŒ–ä½œä¸ºä»£ç†ï¼‰
            momentum_score = hot_score * 0.8  # ç®€åŒ–å¤„ç†
            
            # å…±æŒ¯å¼ºåº¦ï¼ˆçƒ­é—¨è‚¡æ•°é‡ï¼‰
            resonance_score = 0
            if hot_data:
                hot_count = hot_data.get('hot_count', 0)
                resonance_score = min(100, hot_count * 15)  # æ¯åªçƒ­é—¨è‚¡15åˆ†
            
            # åŠ æƒç»¼åˆå¾—åˆ†
            weights = cls.PARAMS
            total_score = (
                money_score * weights['weight_money_flow'] +
                hot_score * weights['weight_hot_rank'] +
                momentum_score * weights['weight_momentum'] +
                resonance_score * weights['weight_resonance']
            )
            
            details = {
                'money_score': round(money_score, 2),
                'hot_score': round(hot_score, 2),
                'momentum_score': round(momentum_score, 2),
                'resonance_score': round(resonance_score, 2),
                'money_data': money_data,
                'hot_data': hot_data,
                'source_sectors': data['source_sectors'],  # è®°å½•åŸå§‹æ¿å—æ¥æº
            }
            
            scores.append((virtual_name, total_score, details))
        
        # æŒ‰å¾—åˆ†é™åºæ’åº
        scores.sort(key=lambda x: x[1], reverse=True)
        
        return scores
    
    @classmethod
    def _generate_sector_predictions(cls, sector_scores: List, sector_analysis: Dict, hot_analysis: Dict) -> List[Dict]:
        """
        ç”Ÿæˆæ¿å—é¢„æµ‹
        """
        predictions = []
        
        for sector_name, score, details in sector_scores[:10]:  # å–å‰10ä¸ª
            money_data = details.get('money_data', {})
            hot_data = details.get('hot_data', {})
            
            # ç”Ÿæˆé¢„æµ‹ç†ç”±
            reasons = []
            
            # èµ„é‡‘æµå‘ç†ç”±
            if money_data:
                inflow = money_data.get('inflow_total', 0)
                if inflow > 5000:
                    reasons.append(f"ä¸»åŠ›èµ„é‡‘å‡€æµå…¥{inflow/10000:.2f}äº¿")
                trend = money_data.get('inflow_trend', 0)
                if trend > 0:
                    reasons.append("èµ„é‡‘æµå…¥å‘ˆä¸Šå‡è¶‹åŠ¿")
                accel = money_data.get('inflow_acceleration', 0)
                if accel > 0:
                    reasons.append("èµ„é‡‘æµå…¥åŠ é€Ÿ")
            
            # çƒ­åº¦ç†ç”±
            if hot_data:
                hot_count = hot_data.get('hot_count', 0)
                if hot_count >= 5:
                    reasons.append(f"{hot_count}åªä¸ªè‚¡è¿›å…¥çƒ­åº¦æ¦œ")
                avg_rank = hot_data.get('avg_rank', 999)
                if avg_rank < 50:
                    reasons.append(f"å¹³å‡çƒ­åº¦æ’åç¬¬{int(avg_rank)}")
            
            if not reasons:
                reasons.append("ç»¼åˆæŠ€æœ¯é¢å‘å¥½")
            
            prediction = {
                'sector_name': sector_name,
                'score': round(score, 2),
                'prediction_level': 'high' if score >= 70 else ('medium' if score >= 50 else 'low'),
                'reasons': reasons[:3],  # æœ€å¤š3ä¸ªç†ç”±
                'details': {
                    'money_score': details['money_score'],
                    'hot_score': details['hot_score'],
                    'hot_count': hot_data.get('hot_count', 0) if hot_data else 0,
                    'inflow_total': money_data.get('inflow_total', 0) if money_data else 0,
                },
                'top_stocks': hot_data.get('top_stocks', [])[:3] if hot_data else [],
            }
            
            predictions.append(prediction)
        
        return predictions
    
    @classmethod
    def _recommend_stocks(cls, sector_predictions: List[Dict], trade_date: date) -> List[Dict]:
        """
        ä»é¢„æµ‹æ¿å—ä¸­ç­›é€‰æ¨èä¸ªè‚¡
        
        ç®—æ³•ï¼š
        1. ä»topæ¿å—ä¸­è·å–å€™é€‰è‚¡
        2. ç»“åˆæŠ€æœ¯æŒ‡æ ‡ã€èµ„é‡‘æµå‘ç­›é€‰
        3. ç»¼åˆè¯„åˆ†æ’åº
        """
        try:
            candidates = []
            
            # ä»é¢„æµ‹æ¿å—ä¸­æ”¶é›†å€™é€‰è‚¡
            for pred in sector_predictions[:cls.PARAMS['top_sectors']]:
                sector_name = pred['sector_name']
                sector_score = pred['score']
                
                top_stocks = pred.get('top_stocks', [])
                for stock in top_stocks[:cls.PARAMS['top_stocks_per_sector']]:
                    candidates.append({
                        'sheep_code': stock['sheep_code'],
                        'sheep_name': stock['sheep_name'],
                        'sector_name': sector_name,
                        'sector_score': sector_score,
                        'hot_rank': stock.get('rank', 999),
                        'hot_score': stock.get('hot_score', 0),
                    })
            
            if not candidates:
                return []
            
            # è·å–å€™é€‰è‚¡çš„è¯¦ç»†æ•°æ®
            sheep_codes = [c['sheep_code'] for c in candidates]
            stock_details = cls._get_stock_details(sheep_codes, trade_date)
            
            # è®¡ç®—æ¯åªè‚¥ç¾Šçš„æ¨èå¾—åˆ†
            recommendations = []
            for cand in candidates:
                sheep_code = cand['sheep_code']
                details = stock_details.get(sheep_code, {})
                
                # ä½¿ç”¨è¯¦ç»†æ•°æ®ä¸­çš„åç§°æ›´æ–°å€™é€‰è‚¡åç§°ï¼ˆç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è‚¥ç¾Šåç§°ï¼‰
                sheep_name = cand['sheep_name']
                if details.get('sheep_name') and details['sheep_name'] != sheep_code:
                    sheep_name = details['sheep_name']
                
                # åŸºç¡€åˆ†ï¼ˆæ¿å—å¾—åˆ†ï¼‰
                base_score = cand['sector_score'] * 0.4
                
                # çƒ­åº¦æ’ååˆ†ï¼ˆæ’åè¶Šé å‰è¶Šé«˜ï¼‰
                rank_score = max(0, (200 - cand['hot_rank'])) * 0.2
                
                # æŠ€æœ¯é¢åˆ†
                tech_score = 0
                if details:
                    # æ¶¨å¹…é€‚ä¸­ï¼ˆ2%-8%æœ€ä½³ï¼‰
                    change_pct = details.get('change_pct', 0)
                    if 2 <= change_pct <= 8:
                        tech_score += 20
                    elif 0 < change_pct < 2:
                        tech_score += 10
                    
                    # é‡æ¯”ï¼ˆ1.5-3æœ€ä½³ï¼‰
                    volume_ratio = details.get('volume_ratio', 1)
                    if 1.5 <= volume_ratio <= 3:
                        tech_score += 15
                    elif volume_ratio > 1:
                        tech_score += 5
                    
                    # èµ„é‡‘æµå…¥
                    main_inflow = details.get('main_net_inflow', 0)
                    if main_inflow > 0:
                        tech_score += min(15, main_inflow / 1000 * 5)
                
                total_score = base_score + rank_score + tech_score
                
                if total_score >= cls.PARAMS['min_stock_score']:
                    # ç”Ÿæˆæ¨èç†ç”±
                    reasons = []
                    reasons.append(f"æ‰€å±æ¿å—ã€{cand['sector_name']}ã€‘èµ„é‡‘æ´»è·ƒ")
                    if cand['hot_rank'] <= 50:
                        reasons.append(f"çƒ­åº¦æ’åç¬¬{cand['hot_rank']}")
                    if details.get('main_net_inflow', 0) > 0:
                        reasons.append(f"ä¸»åŠ›å‡€æµå…¥{details.get('main_net_inflow', 0)/10000:.2f}äº¿")
                    
                    recommendations.append({
                        'sheep_code': sheep_code,
                        'sheep_name': sheep_name,  # ä½¿ç”¨æ›´æ–°åçš„åç§°
                        'sector_name': cand['sector_name'],
                        'score': round(total_score, 2),
                        'hot_rank': cand['hot_rank'],
                        'reasons': reasons[:3],
                        'details': {
                            'change_pct': details.get('change_pct'),
                            'current_price': details.get('close_price'),
                            'main_net_inflow': details.get('main_net_inflow'),
                            'volume_ratio': details.get('volume_ratio'),
                        }
                    })
            
            # æŒ‰å¾—åˆ†æ’åº
            recommendations.sort(key=lambda x: x['score'], reverse=True)
            
            # æŒ‰sheep_codeå»é‡ï¼Œä¿ç•™å¾—åˆ†æœ€é«˜çš„è®°å½•
            seen_codes = set()
            unique_recommendations = []
            for rec in recommendations:
                if rec['sheep_code'] not in seen_codes:
                    seen_codes.add(rec['sheep_code'])
                    unique_recommendations.append(rec)
            
            return unique_recommendations[:cls.PARAMS['total_recommended_stocks']]
            
        except Exception as e:
            logger.error(f"ç­›é€‰æ¨èä¸ªè‚¡å¤±è´¥: {e}", exc_info=True)
            return []
    
    @classmethod
    def _get_stock_details(cls, sheep_codes: List[str], trade_date: date) -> Dict[str, Dict]:
        """è·å–è‚¥ç¾Šè¯¦ç»†æ•°æ®ï¼ˆåŒ…å«è‚¥ç¾Šåç§°ï¼‰"""
        if not sheep_codes:
            return {}
        
        try:
            with get_db() as db:
                # æ„å»ºå‚æ•°åŒ–æŸ¥è¯¢
                placeholders = ','.join([f':code_{i}' for i in range(len(sheep_codes))])
                params = {f'code_{i}': code for i, code in enumerate(sheep_codes)}
                params['trade_date'] = trade_date
                
                # è·å–æ—¥Kæ•°æ®å’Œè‚¥ç¾Šåç§°
                query = text(f"""
                    SELECT 
                        sd.sheep_code,
                        sb.sheep_name,
                        sd.close_price,
                        sd.change_pct,
                        sd.volume,
                        sd.turnover_rate,
                        (SELECT AVG(volume) FROM sheep_daily sd2 
                         WHERE sd2.sheep_code = sd.sheep_code 
                         AND sd2.trade_date < :trade_date
                         ORDER BY sd2.trade_date DESC LIMIT 5) as avg_volume_5
                    FROM sheep_daily sd
                    LEFT JOIN sheep_basic sb ON sd.sheep_code = sb.sheep_code AND sb.is_active = 1
                    WHERE sd.sheep_code IN ({placeholders})
                    AND sd.trade_date = :trade_date
                """)
                
                result = db.execute(query, params)
                rows = result.fetchall()
                
                details = {}
                for row in rows:
                    sheep_code = row[0]
                    avg_volume = float(row[6]) if row[6] else 1
                    current_volume = float(row[4]) if row[4] else 0
                    volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1
                    
                    details[sheep_code] = {
                        'sheep_name': row[1] if row[1] else sheep_code,
                        'close_price': float(row[2]) if row[2] else 0,
                        'change_pct': float(row[3]) if row[3] else 0,
                        'volume': current_volume,
                        'turnover_rate': float(row[5]) if row[5] else 0,
                        'volume_ratio': round(volume_ratio, 2),
                    }
                
                # è·å–èµ„é‡‘æµå‘æ•°æ®
                flow_query = text(f"""
                    SELECT sheep_code, main_net_inflow
                    FROM sheep_money_flow
                    WHERE sheep_code IN ({placeholders})
                    AND trade_date = :trade_date
                """)
                
                flow_result = db.execute(flow_query, params)
                for row in flow_result:
                    sheep_code = row[0]
                    if sheep_code in details:
                        details[sheep_code]['main_net_inflow'] = float(row[1]) if row[1] else 0
                
                return details
                
        except Exception as e:
            logger.error(f"è·å–è‚¥ç¾Šè¯¦ç»†æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}
    
    @classmethod
    def _generate_prediction_description(cls, sector_predictions: List, stock_recommendations: List, trade_date: date) -> str:
        """ç”Ÿæˆé¢„æµ‹æè¿°æ–‡æœ¬"""
        if not sector_predictions:
            return "æš‚æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆé¢„æµ‹"
        
        desc_parts = []
        
        # å¼€å¤´
        desc_parts.append(f"ã€æ˜æ—¥çƒ­ç‚¹é¢„åˆ¤ã€‘åŸºäº{trade_date}å¸‚åœºæ•°æ®åˆ†æ:")
        desc_parts.append("")
        
        # æ¿å—é¢„æµ‹
        top_sectors = sector_predictions[:3]
        if top_sectors:
            sector_names = [s['sector_name'] for s in top_sectors]
            desc_parts.append(f"ğŸ“ˆ é‡ç‚¹å…³æ³¨æ¿å—ï¼š{' / '.join(sector_names)}")
            desc_parts.append("")
            
            for i, pred in enumerate(top_sectors, 1):
                score = pred['score']
                level_emoji = "ğŸ”¥" if score >= 70 else ("â­" if score >= 50 else "ğŸ’¡")
                reasons = 'ï¼Œ'.join(pred['reasons'][:2])
                desc_parts.append(f"{i}. {level_emoji} {pred['sector_name']}ï¼ˆè¯„åˆ†{score:.0f}åˆ†ï¼‰")
                desc_parts.append(f"   ç†ç”±ï¼š{reasons}")
        
        # ä¸ªè‚¡æ¨è
        if stock_recommendations:
            desc_parts.append("")
            desc_parts.append(f"ğŸ“Š ç²¾é€‰ä¸ªè‚¡ï¼ˆå…±{len(stock_recommendations)}åªï¼‰ï¼š")
            for i, rec in enumerate(stock_recommendations[:5], 1):
                desc_parts.append(f"  {i}. {rec['sheep_name']}ï¼ˆ{rec['sheep_code']}ï¼‰- {rec['sector_name']}")
        
        # é£é™©æç¤º
        desc_parts.append("")
        desc_parts.append("âš ï¸ ä»¥ä¸Šåˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ï¼Œè¯·æ³¨æ„é£é™©æ§åˆ¶ã€‚")
        
        return '\n'.join(desc_parts)
    
    @classmethod
    def _get_cached_prediction(cls, target_date: date) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„é¢„æµ‹ç»“æœ"""
        try:
            with get_db() as db:
                query = text("""
                    SELECT prediction_data
                    FROM next_day_prediction_cache
                    WHERE target_date = :target_date
                    ORDER BY created_at DESC
                    LIMIT 1
                """)
                result = db.execute(query, {'target_date': target_date})
                row = result.fetchone()
                if row and row[0]:
                    return json.loads(row[0])
        except Exception as e:
            logger.warning(f"è·å–é¢„æµ‹ç¼“å­˜å¤±è´¥: {e}")
        return None
    
    @classmethod
    def _save_prediction_cache(cls, target_date: date, prediction: Dict):
        """ä¿å­˜é¢„æµ‹ç»“æœåˆ°ç¼“å­˜"""
        try:
            with get_db() as db:
                # å…ˆåˆ é™¤æ—§çš„ç¼“å­˜
                db.execute(text("""
                    DELETE FROM next_day_prediction_cache
                    WHERE target_date = :target_date
                """), {'target_date': target_date})
                
                # æ’å…¥æ–°çš„ç¼“å­˜
                db.execute(text("""
                    INSERT INTO next_day_prediction_cache (target_date, prediction_data, created_at)
                    VALUES (:target_date, :prediction_data, :created_at)
                """), {
                    'target_date': target_date,
                    'prediction_data': json.dumps(prediction, ensure_ascii=False, default=str),
                    'created_at': datetime.now(),
                })
                db.commit()
                logger.info(f"é¢„æµ‹ç»“æœå·²ç¼“å­˜: {target_date}")
        except Exception as e:
            logger.error(f"ä¿å­˜é¢„æµ‹ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
    
    @classmethod
    def get_latest_prediction(cls) -> Optional[Dict]:
        """
        è·å–æœ€æ–°çš„é¢„æµ‹ç»“æœï¼ˆä¾›APIè°ƒç”¨ï¼‰
        
        å¦‚æœç¼“å­˜è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆæ–°çš„é¢„æµ‹
        """
        return cls.generate_prediction(force=False)
